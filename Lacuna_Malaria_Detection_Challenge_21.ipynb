{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check GPU type\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "M2tI4-UazHJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ultralytics\n",
        "!pip -q install  ultralytics"
      ],
      "metadata": {
        "id": "TdOXNzYR1d32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEIlI7wOGP-R"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4CYdHqwnzcU",
        "outputId": "bdbaff50-a8a8-4a62-c571-965d76a8d715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozqm5yKJGuV4",
        "outputId": "f6fb4136-5d58-46e1-818d-e832a7fba701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['images.zip', 'Test.csv', '.ipynb_checkpoints', 'Train.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Path to where your data is stored\n",
        "DATA_DIR = Path('/content/drive/MyDrive/Lacuna')\n",
        "\n",
        "# Preview data files available\n",
        "os.listdir(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYL1hmTCP6d0"
      },
      "outputs": [],
      "source": [
        "# Set up directoris for training a yolo model\n",
        "\n",
        "# Images directories\n",
        "DATASET_DIR = Path('datasets/dataset')\n",
        "IMAGES_DIR = DATASET_DIR / 'images'\n",
        "TRAIN_IMAGES_DIR = IMAGES_DIR / 'train'\n",
        "VAL_IMAGES_DIR = IMAGES_DIR / 'val'\n",
        "TEST_IMAGES_DIR = IMAGES_DIR / 'test'\n",
        "\n",
        "# Labels directories\n",
        "LABELS_DIR = DATASET_DIR / 'labels'\n",
        "TRAIN_LABELS_DIR = LABELS_DIR / 'train'\n",
        "VAL_LABELS_DIR = LABELS_DIR / 'val'\n",
        "TEST_LABELS_DIR = LABELS_DIR / 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COCyht5BGuQV"
      },
      "outputs": [],
      "source": [
        "# Unzip images to 'images' dir\n",
        "shutil.unpack_archive(DATA_DIR / 'images.zip', 'images')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test files\n",
        "train = pd.read_csv(DATA_DIR / 'Train.csv')\n",
        "test = pd.read_csv(DATA_DIR / 'Test.csv')\n",
        "#ss = pd.read_csv(DATA_DIR / 'SampleSubmission.csv')\n",
        "\n",
        "# Add an image_path column\n",
        "train['image_path'] = [Path('images/' + x) for x in train.Image_ID]\n",
        "test['image_path'] = [Path('images/' + x) for x in test.Image_ID]\n",
        "\n",
        "# Map str classes to ints (label encoding targets)\n",
        "train['class_id'] = train['class'].map({'Trophozoite': 0, 'WBC': 1, 'NEG': 2})\n",
        "\n",
        "# Preview the head of the train set\n",
        "train.head()"
      ],
      "metadata": {
        "id": "KAeH30Kg1o6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cro7Tqtzxd_g"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = train[~(train['class'] == 'NEG')].reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17zUCoWWT6JO",
        "outputId": "eca9eede-09d2-40f5-f31f-2267a5b24bd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17354, 9), (5488, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Split data into training and validation\n",
        "train_unique_imgs_df = train.drop_duplicates(subset = ['Image_ID'], ignore_index = True)\n",
        "X_train, X_val = train_test_split(train_unique_imgs_df, test_size = 0.25, stratify=train_unique_imgs_df['class'], random_state=42)\n",
        "\n",
        "X_train = train[train.Image_ID.isin(X_train.Image_ID)]\n",
        "X_val = train[train.Image_ID.isin(X_val.Image_ID)]\n",
        "\n",
        "# Check shapes of training and validation data\n",
        "X_train.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview target distribution, seems there a class imbalance that needs to be handled\n",
        "X_train['class'].value_counts(normalize = True), X_val['class'].value_counts(normalize = True)"
      ],
      "metadata": {
        "id": "mhBBjN-Z1yfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePBUqMMzGuOC"
      },
      "outputs": [],
      "source": [
        "# Check if dirs exist, if they do, remove them, otherwise create them.\n",
        "# This only needs to run once\n",
        "for DIR in [TRAIN_IMAGES_DIR,VAL_IMAGES_DIR, TEST_IMAGES_DIR, TRAIN_LABELS_DIR,VAL_LABELS_DIR,TEST_LABELS_DIR]:\n",
        "  if DIR.exists():\n",
        "    shutil.rmtree(DIR)\n",
        "  DIR.mkdir(parents=True, exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy train, val and test images to their respective dirs\n",
        "for img in tqdm(X_train.image_path.unique()):\n",
        "  shutil.copy(img, TRAIN_IMAGES_DIR / img.parts[-1])\n",
        "\n",
        "for img in tqdm(X_val.image_path.unique()):\n",
        "  shutil.copy(img, VAL_IMAGES_DIR / img.parts[-1])\n",
        "\n",
        "for img in tqdm(test.image_path.unique()):\n",
        "  shutil.copy(img, TEST_IMAGES_DIR / img.parts[-1])"
      ],
      "metadata": {
        "id": "Ug0Uxv4Y12Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert the bboxes to yolo format and save them\n",
        "def save_yolo_annotation(row):\n",
        "    image_path, class_id, output_dir = row['image_path'], row['class_id'], row['output_dir']\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image from path: {image_path}\")\n",
        "\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    label_file = Path(output_dir) / f\"{Path(image_path).stem}.txt\"\n",
        "\n",
        "    ymin, xmin, ymax, xmax = row['ymin'], row['xmin'], row['ymax'], row['xmax']\n",
        "\n",
        "    # Normalize the coordinates\n",
        "    x_center = (xmin + xmax) / 2 / width\n",
        "    y_center = (ymin + ymax) / 2 / height\n",
        "    bbox_width = (xmax - xmin) / width\n",
        "    bbox_height = (ymax - ymin) / height\n",
        "\n",
        "    with open(label_file, 'a') as f:\n",
        "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
        "\n",
        "# Parallelize the annotation saving process\n",
        "def process_dataset(dataframe, output_dir):\n",
        "    dataframe['output_dir'] = output_dir\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        list(tqdm(pool.imap(save_yolo_annotation, dataframe.to_dict('records')), total=len(dataframe)))\n",
        "\n",
        "# Save train and validation labels to their respective dirs\n",
        "process_dataset(X_train, TRAIN_LABELS_DIR)\n",
        "process_dataset(X_val, VAL_LABELS_DIR)"
      ],
      "metadata": {
        "id": "iiYDVb2418kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ka7dY4iH1U",
        "outputId": "7dfa32bb-22ef-4664-95d8-00db1a114a74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('datasets/dataset/images/train')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Train images dir\n",
        "TRAIN_IMAGES_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYrPsLMHIyW_",
        "outputId": "9c2dccc6-7d6d-48df-82e7-8b71a9df6c83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': '/content/datasets/dataset/images/train',\n",
              " 'val': '/content/datasets/dataset/images/val',\n",
              " 'test': '/content/datasets/dataset/images/test',\n",
              " 'nc': 2,\n",
              " 'names': ['Trophozoite', 'WBC']}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Create a data.yaml file required by yolo\n",
        "class_names = train['class'].unique().tolist()\n",
        "num_classes = len(class_names)\n",
        "\n",
        "data_yaml = {\n",
        "    'train': '/content/' + str(TRAIN_IMAGES_DIR),\n",
        "    'val': '/content/' + str(VAL_IMAGES_DIR),\n",
        "    'test': '/content/' + str(TEST_IMAGES_DIR),\n",
        "    'nc': num_classes,\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "yaml_path = 'data.yaml'\n",
        "with open(yaml_path, 'w') as file:\n",
        "    yaml.dump(data_yaml, file, default_flow_style=False)\n",
        "\n",
        "# Preview data yaml file\n",
        "data_yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot some images and their bboxes to ensure the conversion was done correctly\n",
        "def load_annotations(label_path):\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    boxes = []\n",
        "    for line in lines:\n",
        "        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
        "        boxes.append((class_id, x_center, y_center, width, height))\n",
        "    return boxes\n",
        "\n",
        "# Function to plot an image with its bounding boxes\n",
        "def plot_image_with_boxes(image_path, boxes):\n",
        "    # Load the image\n",
        "    image = cv2.imread(str(image_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Get image dimensions\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    # Plot the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # Plot each bounding box\n",
        "    for box in boxes:\n",
        "        class_id, x_center, y_center, width, height = box\n",
        "        # Convert YOLO format to corner coordinates\n",
        "        xmin = int((x_center - width / 2) * w)\n",
        "        ymin = int((y_center - height / 2) * h)\n",
        "        xmax = int((x_center + width / 2) * w)\n",
        "        ymax = int((y_center + height / 2) * h)\n",
        "\n",
        "        # Draw the bounding box\n",
        "        plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                          edgecolor='red', facecolor='none', linewidth=2))\n",
        "        plt.text(xmin, ymin - 10, f'Class {int(class_id)}', color='red', fontsize=12, weight='bold')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Directories for images and labels\n",
        "IMAGE_DIR = TRAIN_IMAGES_DIR\n",
        "LABEL_DIR = TRAIN_LABELS_DIR\n",
        "\n",
        "# Plot a few images with their annotations\n",
        "for image_name in os.listdir(IMAGE_DIR)[:3]:\n",
        "    image_path = IMAGE_DIR / image_name\n",
        "    label_path = LABEL_DIR / (image_name.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
        "\n",
        "    if label_path.exists():\n",
        "        boxes = load_annotations(label_path)\n",
        "        print(f\"Plotting {image_name} with {len(boxes)} bounding boxes.\")\n",
        "        plot_image_with_boxes(image_path, boxes)\n",
        "    else:\n",
        "        print(f\"No annotations found for {image_name}.\")"
      ],
      "metadata": {
        "id": "5eLx61ICzqWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sldeq5zZykRD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Set environment variable to avoid memory fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Load the smallest YOLO model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Fine tune model to our data\n",
        "model.train(\n",
        "    data='data.yaml',          # Path to the dataset configuration\n",
        "    epochs=40,                 # Number of epochs\n",
        "    imgsz=416,                 # Further reduced image size\n",
        "    batch=32,                   # Minimal batch size\n",
        "    device=0,              # Use CPU for training (slower but should work)\n",
        "    workers=0,                 # No worker threads to reduce memory usage\n",
        "    patience=5,\n",
        "    lr0=0.0001,\n",
        "    lrf=0.01,\n",
        "    optimizer='Adam',\n",
        "    momentum=0.937,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=3,\n",
        "    warmup_momentum=0.8,\n",
        "    warmup_bias_lr=0.1,\n",
        "    amp=False                  # Disable mixed precision training on CPU\n",
        ")"
      ],
      "metadata": {
        "id": "yP6RocHZz53F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model on the validation set\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "results = model.val()"
      ],
      "metadata": {
        "id": "jTXBB5Tb0De6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained YOLO model\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Path to the test images directory\n",
        "test_dir_path = '/content/datasets/dataset/images/test'\n",
        "\n",
        "# Get a list of all image files in the test directory\n",
        "image_files = os.listdir(test_dir_path)\n",
        "\n",
        "# Initialize an empty list to store the results for all images\n",
        "all_data = []\n",
        "\n",
        "# Iterate through each image in the directory\n",
        "for image_file in tqdm(image_files):\n",
        "    # Full path to the image\n",
        "    img_path = os.path.join(test_dir_path, image_file)\n",
        "\n",
        "    # Make predictions on the image\n",
        "    results = model(img_path)\n",
        "\n",
        "    # Extract bounding boxes, confidence scores, and class labels\n",
        "    boxes = results[0].boxes.xyxy.tolist()  # Bounding boxes in xyxy format\n",
        "    classes = results[0].boxes.cls.tolist()  # Class indices\n",
        "    confidences = results[0].boxes.conf.tolist()  # Confidence scores\n",
        "    names = results[0].names  # Class names dictionary\n",
        "\n",
        "    if not boxes:\n",
        "        # If no detections, add NEG as the class\n",
        "        all_data.append({\n",
        "            'Image_ID': image_file,\n",
        "            'class': 'NEG',\n",
        "            'confidence': 1.0,  # You can set this to a default value\n",
        "            'ymin': 0,  # Default value (no detection)\n",
        "            'xmin': 0,  # Default value (no detection)\n",
        "            'ymax': 0,  # Default value (no detection)\n",
        "            'xmax': 0   # Default value (no detection)\n",
        "        })\n",
        "    else:\n",
        "        # Iterate through the results for this image\n",
        "        for box, cls, conf in zip(boxes, classes, confidences):\n",
        "            x1, y1, x2, y2 = box\n",
        "            detected_class = names[int(cls)]  # Get the class name from the names dictionary\n",
        "\n",
        "            # Add the result to the all_data list\n",
        "            all_data.append({\n",
        "                'Image_ID': image_file,\n",
        "                'class': detected_class,\n",
        "                'confidence': conf,\n",
        "                'ymin': y1,\n",
        "                'xmin': x1,\n",
        "                'ymax': y2,\n",
        "                'xmax': x2\n",
        "            })\n",
        "\n",
        "# Convert the list to a DataFrame for all images\n",
        "sub = pd.DataFrame(all_data)"
      ],
      "metadata": {
        "id": "KKhvGjAW0LQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub.head()"
      ],
      "metadata": {
        "id": "jNuOaWPH2DFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub['class'].value_counts()"
      ],
      "metadata": {
        "id": "pNNASukl2GK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI-i73Rm2CnH"
      },
      "outputs": [],
      "source": [
        "# Create submission file to be uploaded to Zindi for scoring\n",
        "sub.to_csv('malaria_submission 1.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
